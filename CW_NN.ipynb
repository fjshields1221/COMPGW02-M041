{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import collections as col\n",
    "import re\n",
    "import random\n",
    "import sklearn\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "#from sklearn.svm import LinearSVC\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "#from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.metrics import auc,roc_curve\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train_feat = pd.DataFrame.from_csv('Model/train_feat_encoded.csv')\n",
    "df_train_y = pd.DataFrame.from_csv('Model/train_y.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_feat_ar= df_train_feat.as_matrix()\n",
    "train_y_ar= df_train_y.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_i = tf.placeholder(\"float\", [None, 215])\n",
    "y_gold = tf.placeholder(\"float\", [None, 1])\n",
    "\n",
    "d_in = 215\n",
    "d_hidden1 = 500\n",
    "d_hidden2 = 500\n",
    "d_hidden3 = 500\n",
    "d_out = 1\n",
    "\n",
    "W1 = tf.Variable(tf.random_normal([d_in, d_hidden1], mean= 0.01, stddev= 0.01))\n",
    "b1 = tf.Variable(tf.random_normal([d_hidden1], mean= 0.01, stddev= 0.01))\n",
    "W2 = tf.Variable(tf.random_normal([d_hidden1, d_hidden2], mean= 0.01, stddev= 0.01))\n",
    "b2 = tf.Variable(tf.random_normal([d_hidden2], mean= 0.01, stddev= 0.01))\n",
    "W3 = tf.Variable(tf.random_normal([d_hidden2, d_hidden3], mean= 0.01, stddev= 0.01))\n",
    "b3 = tf.Variable(tf.random_normal([d_hidden3], mean= 0.01, stddev= 0.01))\n",
    "W4 = tf.Variable(tf.random_normal([d_hidden3, d_out], mean= 0.01, stddev= 0.01))\n",
    "b4 = tf.Variable(tf.random_normal([d_out], mean= 0.01, stddev= 0.01))\n",
    "\n",
    "a1_i = tf.matmul(x_i, W1)+ b1\n",
    "z1_i = tf.sigmoid(a1_i)\n",
    "a2_i = tf.matmul(z1_i, W2)+ b2\n",
    "z2_i = tf.sigmoid(a2_i)\n",
    "a3_i = tf.matmul(z2_i, W3)+ b3\n",
    "z3_i = tf.sigmoid(a3_i)\n",
    "a4_i = tf.matmul(z3_i, W4)+ b4\n",
    "y_hat = tf.sigmoid(a4_i)\n",
    "\n",
    "loss = tf.pow((y_hat- y_gold), 2)\n",
    "#cross_entropy = -tf.reduce_sum(y_gold* tf.log(tf.clip_by_value(P_ij, 1e-10, 1.0)))\n",
    "optimiser = tf.train.GradientDescentOptimizer(0.005).minimize(loss)\n",
    "\n",
    "prediction = tf.round(y_hat)\n",
    "mistakes = tf.not_equal(y_gold, prediction)\n",
    "accuracy = 1- tf.reduce_mean(tf.cast(mistakes, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train and test\n",
    "batch_sz= 30\n",
    "iter_= int(Xi.shape[0]/ batch_sz)\n",
    "epoch= 10\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    #load_model()\n",
    "    \n",
    "    init_dict= {x_i: Xi[:10000],\n",
    "                y_gold: P_target_r[:10000]}\n",
    "    print('Init train accuracy:', (sess.run(accuracy, feed_dict= init_dict)))\n",
    "    \n",
    "    test_dict= {x_i: val_Xi[10000:20000],\n",
    "                y_gold: val_P_target_r[10000:20000]} \n",
    "    print('Init test accuracy:', (sess.run(accuracy, feed_dict= test_dict)))\n",
    "    \n",
    "    for e in range(epoch):\n",
    "        e_loss= 0\n",
    "        \n",
    "        for i in range(iter_):\n",
    "            i_loss= 0\n",
    "            sta= i* batch_sz\n",
    "            end= (i+ 1)* batch_sz\n",
    "            iter_dict= {x_i: Xi[sta: end],\n",
    "                        y_gold: P_target_r[sta: end]}\n",
    "            sess.run(optimiser, feed_dict= iter_dict)\n",
    "            e_loss+= sess.run(cross_entropy, feed_dict= iter_dict)\n",
    "        \n",
    "        if e% (epoch/ 10)== 0:\n",
    "            print('Epoch', e, 'loss:', e_loss)\n",
    "            print('Epoch train/test accur:', (sess.run(accuracy, feed_dict= init_dict)), (sess.run(accuracy, feed_dict= test_dict)))\n",
    "            \n",
    "        if (sess.run(accuracy, feed_dict= test_dict)) > 0.4:\n",
    "            save_model(sess)\n",
    "        \n",
    "    print('Final train accuracy:', (sess.run(accuracy, feed_dict= init_dict)))\n",
    "    print('Final test accuracy:', (sess.run(accuracy, feed_dict= test_dict)))\n",
    "    \n",
    "    # TensorFlow save model\n",
    "    save_model(sess)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
