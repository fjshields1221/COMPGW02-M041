{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import collections as col\n",
    "import re\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import sklearn\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import csv\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train= pd.read_csv('dataset/train.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train= pd.read_csv('dataset/validation.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def enc_day(X):\n",
    "    X = pd.concat([X,pd.get_dummies(X.weekday,prefix='day')],axis=1)\n",
    "    X = X.drop('weekday',axis=1)\n",
    "    return X\n",
    "\n",
    "# 2. Encode hours\n",
    "def enc_hrs(X):\n",
    "    X = pd.concat([X,pd.get_dummies(X.hour,prefix='hour')],axis=1)\n",
    "    X = X.drop('hour',axis=1)\n",
    "    return X\n",
    "\n",
    "# Split user agent into 2 ~ OS and browser\n",
    "def enc_OS_browser(X):\n",
    "    df = pd.DataFrame(X.useragent.str.split('_',1).tolist(),\n",
    "                                   columns = ['OS','browser'])\n",
    "    X = pd.concat([X,df],axis=1)\n",
    "\n",
    "    # 3. Encode OS\n",
    "    X = pd.concat([X,pd.get_dummies(X.OS,prefix='OS')],axis=1)\n",
    "    X = X.drop('OS',axis=1)\n",
    "\n",
    "    # 4. Encode browser\n",
    "    X = pd.concat([X,pd.get_dummies(X.browser,prefix='browser')],axis=1)\n",
    "    X = X.drop('browser',axis=1)\n",
    "    \n",
    "    X = X.drop('useragent',axis=1)\n",
    "    return X\n",
    "\n",
    "# 5. Encode region\n",
    "def enc_region(X):\n",
    "    X = pd.concat([X,pd.get_dummies(X.region,prefix='region')],axis=1)\n",
    "    X = X.drop('region',axis=1)\n",
    "    return X\n",
    "\n",
    "# 6. Encode adexchange\n",
    "def enc_adexchange(X):\n",
    "    X = pd.concat([X,pd.get_dummies(X.adexchange,prefix='adexchange')],axis=1)\n",
    "    X = X.drop('adexchange',axis=1)\n",
    "    return X\n",
    "\n",
    "# 7. Encode slotwidth\n",
    "def enc_slotwidth(X):\n",
    "    X = pd.concat([X,pd.get_dummies(X.slotwidth,prefix='slotwidth')],axis=1)\n",
    "    X = X.drop('slotwidth',axis=1)\n",
    "    return X\n",
    "\n",
    "# 8. Encode slotheight\n",
    "def enc_slotheight(X):\n",
    "    X = pd.concat([X,pd.get_dummies(X.slotheight,prefix='slotheight')],axis=1)\n",
    "    X = X.drop('slotheight',axis=1)\n",
    "    return X\n",
    "\n",
    "# 9. Encode slotvisibility\n",
    "def enc_slotvisibility(X):\n",
    "    X = pd.concat([X,pd.get_dummies(X.slotvisibility,prefix='slotvisibility')],axis=1)\n",
    "    X = X.drop('slotvisibility',axis=1)\n",
    "    return X\n",
    "\n",
    "# 10. Encode slotformat\n",
    "def enc_slotformat(X):\n",
    "    X = pd.concat([X,pd.get_dummies(X.slotformat,prefix='slotformat')],axis=1)\n",
    "    X = X.drop('slotformat',axis=1)\n",
    "    return X\n",
    "\n",
    "# 11. Encode advertiser\n",
    "def enc_advertiser(X):\n",
    "    X = pd.concat([X,pd.get_dummies(X.advertiser,prefix='advertiser')],axis=1)\n",
    "    X = X.drop('advertiser',axis=1)\n",
    "    return X\n",
    "\n",
    "# 12. Encoding slotprice into buckets\n",
    "def enc_slotprice(X):\n",
    "    bins = pd.DataFrame()\n",
    "    bins['slotprice_bins'] = pd.cut(X.slotprice.values,5, labels=[1,2,3,4,5])\n",
    "\n",
    "    X = pd.concat([X,bins],axis=1)\n",
    "    X = pd.concat([X,pd.get_dummies(X.slotprice_bins,prefix='slotprice')],axis=1)\n",
    "\n",
    "    X = X.drop('slotprice',axis=1)\n",
    "    X = X.drop('slotprice_bins',axis=1)\n",
    "    bins.pop('slotprice_bins')\n",
    "    return X\n",
    "\n",
    "# 13. Encoding user tags\n",
    "def enc_usertag(X):\n",
    "    a = pd.DataFrame(X.usertag.str.split(',').tolist())\n",
    "    usertag_df = pd.DataFrame(a)\n",
    "    usertag_df2 = pd.get_dummies(usertag_df,prefix='usertag')\n",
    "    usertag_df2 = usertag_df2.groupby(usertag_df2.columns, axis=1).sum()\n",
    "    X = pd.concat([X, usertag_df2], axis=1)\n",
    "    X = X.drop('usertag', axis=1)\n",
    "    return X\n",
    "\n",
    "\n",
    "# 14. Encoding cities\n",
    "def enc_city(X):\n",
    "    X = pd.concat([X,pd.get_dummies(X.city,prefix='city')],axis=1)\n",
    "    X = X.drop('city',axis=1)\n",
    "    return X\n",
    "\n",
    "start_encode = time.time()\n",
    "\n",
    "def encode_labels(X):\n",
    "    X = enc_day(X)\n",
    "    X = enc_hrs(X)\n",
    "    X = enc_OS_browser(X)\n",
    "    X = enc_region(X)\n",
    "    X = enc_adexchange(X)\n",
    "    X = enc_slotwidth(X)\n",
    "    X = enc_slotheight(X)\n",
    "    X = enc_slotvisibility(X)\n",
    "    X = enc_slotformat(X)\n",
    "    X = enc_advertiser(X)\n",
    "#    X = enc_city(X)    # Don't encode cities\n",
    "    X = enc_slotprice(X)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = encode_labels(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = enc_usertag(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y_train= pd.DataFrame(X_train[['click', 'payprice']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y_train['click_payprice']= (Y_train['click'])/ Y_train['payprice']\n",
    "Y_train= Y_train.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y_train['click_payprice_s']= (Y_train['click_payprice']- Y_train['click_payprice'].mean())/ Y_train['click_payprice'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train= X_train.drop(['click', 'bidid', 'logtype', 'userid', 'IP', 'city', 'domain',\n",
    "       'url', 'urlid', 'slotid', 'creative', 'bidprice', 'payprice',\n",
    "       'keypage'], axis= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y_train_s = np.asarray(Y_train)[:, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y_train_s= Y_train_s.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def batch_balance(Y_train_s, X_train, iter_):\n",
    "    sample_sz = 10000\n",
    "    \n",
    "    nclick_index = np.random.randint(sample_sz, size=98)\n",
    "    click_index = np.where(Y_train_s[int(iter_* sample_sz/10) :int((iter_+ 1)* sample_sz/10), 0]> -0.01440388)\n",
    "    click_pos_r = np.random.randint(len(click_index[0]), size=2)\n",
    "    click_index_r = click_index[0][click_pos_r]\n",
    "    Y_click_r = Y_train_s[click_index_r]\n",
    "    X_click_r = np.asarray(X_train)[click_index_r]\n",
    "    Y_nclick_r = Y_train_s[nclick_index]\n",
    "    X_nclick_r = np.asarray(X_train)[nclick_index]\n",
    "    \n",
    "    a = np.append(Y_click_r, Y_nclick_r, axis= 0)\n",
    "    b = np.append(X_click_r, X_nclick_r, axis= 0)\n",
    "    p = np.random.permutation(len(a))\n",
    "    \n",
    "    return a[p], b[p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class pCTR_MLP():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.self = self\n",
    "\n",
    "    def initilise_model(self):\n",
    "        self.x_i = tf.placeholder(\"float\", [None, 219])\n",
    "        self.y_i = tf.placeholder(\"float\", [None, 1])\n",
    "\n",
    "        d_in = 219\n",
    "        d_hidden1 = 500\n",
    "        d_hidden2 = 500\n",
    "        d_out = 1\n",
    "\n",
    "        self.W1 = tf.Variable(tf.random_normal([d_in, d_hidden1], mean= 0.01, stddev= 0.01))\n",
    "        self.b1 = tf.Variable(tf.random_normal([d_hidden1], mean= -2, stddev= 0.01))\n",
    "        self.W2 = tf.Variable(tf.random_normal([d_hidden1, d_hidden2], mean= 0.01, stddev= 0.01))\n",
    "        self.b2 = tf.Variable(tf.random_normal([d_hidden2], mean= -2, stddev= 0.01))\n",
    "        self.W3 = tf.Variable(tf.random_normal([d_hidden2, d_out], mean= 0.01, stddev= 0.01))\n",
    "        self.b3 = tf.Variable(tf.random_normal([d_out], mean= -1, stddev= 0.01))\n",
    "\n",
    "        self.a1_i = tf.matmul(self.x_i, self.W1)+ self.b1\n",
    "        self.z1_i = tf.sigmoid(self.a1_i)\n",
    "        self.a2_i = tf.matmul(self.z1_i, self.W2)+ self.b2\n",
    "        self.z2_i = tf.sigmoid(self.a2_i)\n",
    "        self.a3_i = tf.matmul(self.z2_i, self.W3)+ self.b3\n",
    "        #self.y_hat = tf.tanh(self.a3_i)\n",
    "        self.y_hat = self.a3_i\n",
    "\n",
    "        self.loss = tf.losses.mean_squared_error(self.y_hat, self.y_i)\n",
    "        \n",
    "        self.global_step = tf.Variable(0, trainable=False)\n",
    "        self.starter_learning_rate = 0.001\n",
    "        self.learning_rate = tf.train.exponential_decay(self.starter_learning_rate, self.global_step,\n",
    "                                                   100000, 0.96, staircase=True)\n",
    "        \n",
    "        self.optimiser = tf.train.AdamOptimizer(self.learning_rate).minimize(self.loss) #self.learning_rate\n",
    "        \n",
    "    def show_var_init(self, x_array, y_array, var, n_samples):\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        show_dict= {self.x_i: x_array[:n_samples],\n",
    "                    self.y_i: y_array[:n_samples]} \n",
    "        return sess.run(var, feed_dict= show_dict)\n",
    "    \n",
    "    def show_var(self, x_array, y_array, var, n_samples):\n",
    "        show_dict= {self.x_i: x_array[:n_samples],\n",
    "                    self.y_i: y_array[:n_samples]} \n",
    "        return sess.run(var, feed_dict= show_dict)\n",
    "\n",
    "    def train_full(self, x_array, y_array, epoch, batch_sz):\n",
    "\n",
    "        self.iter_= int(x_array.shape[0]/ batch_sz)\n",
    "        print('Iters: %s. Epoch:  %s' % (self.iter_, epoch))\n",
    "        \n",
    "        #try:\n",
    "        #    self.load_model()\n",
    "        #except:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "\n",
    "        self.train_dict= {self.x_i: x_array,\n",
    "                          self.y_i: y_array} \n",
    "\n",
    "        for e in range(epoch):\n",
    "            e_loss= 0\n",
    "            if e% 10== 0:\n",
    "                print(e)\n",
    "            for i in range(self.iter_):\n",
    "                i_loss= 0\n",
    "\n",
    "                y_batch, x_batch = batch_balance(y_array, x_array, self.iter_)\n",
    "                \n",
    "                iter_dict= {self.x_i: x_batch,\n",
    "                            self.y_i: y_batch}\n",
    "                sess.run(self.optimiser, feed_dict= iter_dict)\n",
    "                e_loss+= sess.run(self.loss, feed_dict= iter_dict)\n",
    "            \n",
    "\n",
    "    def save_model(self, sess):\n",
    "        print('Saving model...')\n",
    "        if not os.path.exists('./pCTR_NNmodel/'):\n",
    "            os.mkdir('./pCTR_NNmodel/')\n",
    "        saver = tf.train.Saver()\n",
    "        saver.save(sess, './pCTR_NNmodel/model.checkpoint')\n",
    "        print('Model saved')\n",
    "\n",
    "    def load_model(self, sess):\n",
    "        print('Loading model...')\n",
    "        saver = tf.train.Saver()\n",
    "        saver.restore(sess, './pCTR_NNmodel/model.checkpoint')\n",
    "        print('Model loaded')\n",
    "\n",
    "    def predict(self, x_array, y_array, save_run= False):\n",
    "        #self.load_model()\n",
    "        pred_dict= {self.x_i: x_array,\n",
    "                    self.y_i: y_array} \n",
    "\n",
    "        predict_proba = sess.run(self.y_hat, feed_dict= pred_dict)\n",
    "        df_predict_proba = pd.DataFrame(predict_proba)\n",
    "\n",
    "        print(df_predict_proba)\n",
    "\n",
    "        if save_run == True:\n",
    "            output_directory = '/pCRT/Val/'\n",
    "            output_filename = 'NN_pCRT_predict_proba.csv'\n",
    "            df_predict_proba.to_csv('NN_pCRT_predict_proba.csv', index= False)\n",
    "            print('pCTR file saved:', os.getcwd(), output_directory, output_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of iterations: 29\n",
      "           0\n",
      "0  -0.013506\n",
      "1  -0.021837\n",
      "2  12.823769\n"
     ]
    }
   ],
   "source": [
    "model = pCTR_MLP()\n",
    "model.initilise_model()\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    disp_y_hat =model.show_var_init(np.asarray(X_train), Y_train_s, model.y_hat, 10)\n",
    "    disp_y =model.show_var_init(np.asarray(X_train), Y_train_s, model.y_i, 10)\n",
    "    \n",
    "    model.train_full(np.asarray(X_train), Y_train_s, 1000, 10000)\n",
    "    model.save_model(sess)\n",
    "    \n",
    "    disp_y_hat2 =model.show_var(np.asarray(X_train), Y_train_s, model.y_hat, 10)\n",
    "    disp_y2 =model.show_var(np.asarray(X_train), Y_train_s, model.y_i, 10)\n",
    "    \n",
    "    model.predict(np.asarray(X_train)[476:479], Y_train_s[476:479])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.03730702],\n",
       "        [ 0.04922843],\n",
       "        [-0.03057742],\n",
       "        [-0.01222038],\n",
       "        [-0.03157938],\n",
       "        [-0.03184783],\n",
       "        [-0.02874517],\n",
       "        [-0.0048573 ],\n",
       "        [-0.0279305 ],\n",
       "        [-0.00551379]], dtype=float32), array([[-0.01440388],\n",
       "        [-0.01440388],\n",
       "        [-0.01440388],\n",
       "        [-0.01440388],\n",
       "        [-0.01440388],\n",
       "        [-0.01440388],\n",
       "        [-0.01440388],\n",
       "        [-0.01440388],\n",
       "        [-0.01440388],\n",
       "        [-0.01440388]], dtype=float32))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disp_y_hat2, disp_y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>click</th>\n",
       "      <th>payprice</th>\n",
       "      <th>click_payprice</th>\n",
       "      <th>click_payprice_s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>0</td>\n",
       "      <td>216</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.014404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>0</td>\n",
       "      <td>248</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.014404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>1</td>\n",
       "      <td>77</td>\n",
       "      <td>0.012987</td>\n",
       "      <td>12.797815</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     click  payprice  click_payprice  click_payprice_s\n",
       "476      0       216        0.000000         -0.014404\n",
       "477      0       248        0.000000         -0.014404\n",
       "478      1        77        0.012987         12.797815"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train[476:479]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.014403883291288463"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(Y_train['click_payprice_s'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Assign requires shapes of both tensors to match. lhs shape= [500] rhs shape= [500,1]\n\t [[Node: save/Assign_6 = Assign[T=DT_FLOAT, _class=[\"loc:@Variable_10\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](Variable_10, save/RestoreV2_6)]]\n\nCaused by op 'save/Assign_6', defined at:\n  File \"/Users/jamesshields/anaconda/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/Users/jamesshields/anaconda/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/Users/jamesshields/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/Users/jamesshields/anaconda/lib/python3.5/site-packages/traitlets/config/application.py\", line 653, in launch_instance\n    app.start()\n  File \"/Users/jamesshields/anaconda/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/Users/jamesshields/anaconda/lib/python3.5/site-packages/zmq/eventloop/ioloop.py\", line 162, in start\n    super(ZMQIOLoop, self).start()\n  File \"/Users/jamesshields/anaconda/lib/python3.5/site-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/Users/jamesshields/anaconda/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/jamesshields/anaconda/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/Users/jamesshields/anaconda/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/Users/jamesshields/anaconda/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/Users/jamesshields/anaconda/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/jamesshields/anaconda/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/Users/jamesshields/anaconda/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/Users/jamesshields/anaconda/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/Users/jamesshields/anaconda/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Users/jamesshields/anaconda/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/Users/jamesshields/anaconda/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Users/jamesshields/anaconda/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/Users/jamesshields/anaconda/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-18-9d4c265c60ab>\", line 4, in <module>\n    model.load_model(sess)\n  File \"<ipython-input-13-32f342d396f3>\", line 86, in load_model\n    saver = tf.train.Saver()\n  File \"/Users/jamesshields/anaconda/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 1051, in __init__\n    self.build()\n  File \"/Users/jamesshields/anaconda/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 1081, in build\n    restore_sequentially=self._restore_sequentially)\n  File \"/Users/jamesshields/anaconda/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 675, in build\n    restore_sequentially, reshape)\n  File \"/Users/jamesshields/anaconda/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 414, in _AddRestoreOps\n    assign_ops.append(saveable.restore(tensors, shapes))\n  File \"/Users/jamesshields/anaconda/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 155, in restore\n    self.op.get_shape().is_fully_defined())\n  File \"/Users/jamesshields/anaconda/lib/python3.5/site-packages/tensorflow/python/ops/gen_state_ops.py\", line 47, in assign\n    use_locking=use_locking, name=name)\n  File \"/Users/jamesshields/anaconda/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 763, in apply_op\n    op_def=op_def)\n  File \"/Users/jamesshields/anaconda/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2395, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/Users/jamesshields/anaconda/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1264, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): Assign requires shapes of both tensors to match. lhs shape= [500] rhs shape= [500,1]\n\t [[Node: save/Assign_6 = Assign[T=DT_FLOAT, _class=[\"loc:@Variable_10\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](Variable_10, save/RestoreV2_6)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/Users/jamesshields/anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jamesshields/anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jamesshields/anaconda/lib/python3.5/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jamesshields/anaconda/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    468\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 469\u001b[0;31m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[1;32m    470\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Assign requires shapes of both tensors to match. lhs shape= [500] rhs shape= [500,1]\n\t [[Node: save/Assign_6 = Assign[T=DT_FLOAT, _class=[\"loc:@Variable_10\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](Variable_10, save/RestoreV2_6)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-9d4c265c60ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitilise_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m#predict(np.asarray(X_train)[476:479], Y_train_s[476:479])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-32f342d396f3>\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(self, sess)\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loading model...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0msaver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSaver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'./pCTR_NNmodel/model.checkpoint'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Model loaded'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jamesshields/anaconda/lib/python3.5/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, sess, save_path)\u001b[0m\n\u001b[1;32m   1437\u001b[0m       \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1438\u001b[0m     sess.run(self.saver_def.restore_op_name,\n\u001b[0;32m-> 1439\u001b[0;31m              {self.saver_def.filename_tensor_name: save_path})\n\u001b[0m\u001b[1;32m   1440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jamesshields/anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jamesshields/anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 965\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jamesshields/anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1015\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1016\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/Users/jamesshields/anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1033\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1035\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1036\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Assign requires shapes of both tensors to match. lhs shape= [500] rhs shape= [500,1]\n\t [[Node: save/Assign_6 = Assign[T=DT_FLOAT, _class=[\"loc:@Variable_10\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](Variable_10, save/RestoreV2_6)]]\n\nCaused by op 'save/Assign_6', defined at:\n  File \"/Users/jamesshields/anaconda/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/Users/jamesshields/anaconda/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/Users/jamesshields/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/Users/jamesshields/anaconda/lib/python3.5/site-packages/traitlets/config/application.py\", line 653, in launch_instance\n    app.start()\n  File \"/Users/jamesshields/anaconda/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/Users/jamesshields/anaconda/lib/python3.5/site-packages/zmq/eventloop/ioloop.py\", line 162, in start\n    super(ZMQIOLoop, self).start()\n  File \"/Users/jamesshields/anaconda/lib/python3.5/site-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/Users/jamesshields/anaconda/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/jamesshields/anaconda/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/Users/jamesshields/anaconda/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/Users/jamesshields/anaconda/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/Users/jamesshields/anaconda/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/jamesshields/anaconda/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/Users/jamesshields/anaconda/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/Users/jamesshields/anaconda/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/Users/jamesshields/anaconda/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Users/jamesshields/anaconda/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/Users/jamesshields/anaconda/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Users/jamesshields/anaconda/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/Users/jamesshields/anaconda/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-18-9d4c265c60ab>\", line 4, in <module>\n    model.load_model(sess)\n  File \"<ipython-input-13-32f342d396f3>\", line 86, in load_model\n    saver = tf.train.Saver()\n  File \"/Users/jamesshields/anaconda/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 1051, in __init__\n    self.build()\n  File \"/Users/jamesshields/anaconda/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 1081, in build\n    restore_sequentially=self._restore_sequentially)\n  File \"/Users/jamesshields/anaconda/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 675, in build\n    restore_sequentially, reshape)\n  File \"/Users/jamesshields/anaconda/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 414, in _AddRestoreOps\n    assign_ops.append(saveable.restore(tensors, shapes))\n  File \"/Users/jamesshields/anaconda/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 155, in restore\n    self.op.get_shape().is_fully_defined())\n  File \"/Users/jamesshields/anaconda/lib/python3.5/site-packages/tensorflow/python/ops/gen_state_ops.py\", line 47, in assign\n    use_locking=use_locking, name=name)\n  File \"/Users/jamesshields/anaconda/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 763, in apply_op\n    op_def=op_def)\n  File \"/Users/jamesshields/anaconda/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2395, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/Users/jamesshields/anaconda/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1264, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): Assign requires shapes of both tensors to match. lhs shape= [500] rhs shape= [500,1]\n\t [[Node: save/Assign_6 = Assign[T=DT_FLOAT, _class=[\"loc:@Variable_10\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](Variable_10, save/RestoreV2_6)]]\n"
     ]
    }
   ],
   "source": [
    "model = pCTR_MLP()\n",
    "model.initilise_model()\n",
    "with tf.Session() as sess:\n",
    "    model.load_model(sess)\n",
    "    \n",
    "    #predict(np.asarray(X_train)[476:479], Y_train_s[476:479])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
